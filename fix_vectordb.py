"""
ë²¡í„°DB ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ê¸°
"""
import os
import json
from pathlib import Path
from typing import List, Dict, Any

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from loguru import logger

class FixedDocumentProcessor:
    def __init__(self, google_api_key: str, persist_directory: str = "./data/chroma_db"):
        """
        ì˜¤ë¥˜ ë°©ì§€ ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        """
        self.google_api_key = google_api_key
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        # Google ì„ë² ë”©ë§Œ ì‚¬ìš© (onnxruntime ë¶ˆí•„ìš”)
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=google_api_key
        )
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        self.vectorstore = None
        logger.info("ì˜¤ë¥˜ ë°©ì§€ ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_accident_cases(self, json_file_path: str) -> List[Document]:
        """íŒë¡€ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                cases = json.load(f)
            
            documents = []
            for case in cases:
                content = f"""
ì‚¬ê³  ìœ í˜•: {case['case_id']}

ì°¨ëŸ‰ A ìƒí™©: {case['vehicle_A_situation']}
ì°¨ëŸ‰ B ìƒí™©: {case['vehicle_B_situation']}

ì‚¬ê³  ì„¤ëª…: {case['accident_description']}
ê³¼ì‹¤ ë¹„ìœ¨: {case['fault_ratio']}
""".strip()
                
                doc = Document(
                    page_content=content,
                    metadata={
                        "case_id": case['case_id'],
                        "fault_ratio": case['fault_ratio'],
                        "source": "accident_case"
                    }
                )
                documents.append(doc)
            
            logger.info(f"íŒë¡€ {len(documents)}ê±´ ë¡œë“œ ì™„ë£Œ")
            return documents
            
        except Exception as e:
            logger.error(f"íŒë¡€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def build_vectorstore_safe(self, documents: List[Document]):
        """ì•ˆì „í•œ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•"""
        if not documents:
            logger.warning("ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        try:
            logger.info("ë¬¸ì„œ ë¶„í•  ì¤‘...")
            chunks = self.text_splitter.split_documents(documents)
            logger.info(f"{len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            
            logger.info("ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì¤‘... (Google ì„ë² ë”© ì‚¬ìš©)")
            
            # ChromaDB ì„¤ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
            self.vectorstore = Chroma.from_documents(
                documents=chunks,
                embedding=self.embeddings,
                persist_directory=str(self.persist_directory),
                collection_name="traffic_accidents"
            )
            
            logger.info("âœ… ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            
            # ëŒ€ì•ˆ: ë‹¨ìˆœ JSON ì €ì¥
            try:
                logger.info("ëŒ€ì•ˆìœ¼ë¡œ JSON íŒŒì¼ì— ì €ì¥...")
                backup_data = {
                    'chunks': [{'content': doc.page_content, 'metadata': doc.metadata} for doc in chunks],
                    'created_at': str(Path(__file__).stat().st_mtime)
                }
                
                backup_file = self.persist_directory / "backup_chunks.json"
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(backup_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"ë°±ì—… ì €ì¥ ì™„ë£Œ: {backup_file}")
                return False
                
            except Exception as backup_error:
                logger.error(f"ë°±ì—… ì €ì¥ë„ ì‹¤íŒ¨: {backup_error}")
                return False
    
    def load_vectorstore_safe(self):
        """ì•ˆì „í•œ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ"""
        try:
            if not self.persist_directory.exists():
                logger.warning("ë²¡í„°ìŠ¤í† ì–´ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ChromaDB ë¡œë“œ ì‹œë„
            self.vectorstore = Chroma(
                persist_directory=str(self.persist_directory),
                embedding_function=self.embeddings,
                collection_name="traffic_accidents"
            )
            
            # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
            test_results = self.vectorstore.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
            logger.info("âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ")
            return self.vectorstore
            
        except Exception as e:
            logger.error(f"ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ë°±ì—… íŒŒì¼ í™•ì¸
            backup_file = self.persist_directory / "backup_chunks.json"
            if backup_file.exists():
                logger.info("ë°±ì—… íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤")
                return "backup_available"
            
            return None

def build_vectordb_safe():
    """ì•ˆì „í•œ ë²¡í„°DB êµ¬ì¶•"""
    from dotenv import load_dotenv
    load_dotenv()
    
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤")
        return
    
    print("ğŸ”§ ì•ˆì „í•œ ë²¡í„°DB êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    processor = FixedDocumentProcessor(api_key)
    
    # íŒë¡€ íŒŒì¼ í™•ì¸
    cases_file = Path("./data/cases/accident_cases.json")
    if not cases_file.exists():
        print("âŒ íŒë¡€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   python main.py --crawl")
        return
    
    # ë¬¸ì„œ ë¡œë“œ
    print("ğŸ“š íŒë¡€ ë°ì´í„° ë¡œë“œ ì¤‘...")
    documents = processor.load_accident_cases(str(cases_file))
    
    if not documents:
        print("âŒ ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # ì•ˆì „í•œ êµ¬ì¶•
    print("âš™ï¸ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì¤‘...")
    success = processor.build_vectorstore_safe(documents)
    
    if success:
        print("âœ… ë²¡í„°DB êµ¬ì¶• ì™„ë£Œ!")
        print("   ì´ì œ python main.py --mvp ë¡œ ì›¹ì•±ì„ ì‹¤í–‰í•˜ì„¸ìš”")
    else:
        print("âš ï¸ ë²¡í„°DB êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆì§€ë§Œ ë°±ì—…ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
        print("   ê¸°ë³¸ ê¸°ëŠ¥ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤")

if __name__ == "__main__":
    build_vectordb_safe()
