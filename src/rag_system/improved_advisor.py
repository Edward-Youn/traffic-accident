"""
ê°œì„ ëœ êµí†µì‚¬ê³  ìë¬¸ ì±—ë´‡ ì‹œìŠ¤í…œ
- ê°„ë‹¨í•œ ì´ˆê¸° ì§„ë‹¨ + ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥
- í•„ìš”ì‹œ ìƒì„¸ ë¶„ì„ìœ¼ë¡œ ì§„í–‰
"""
import os
from typing import List, Dict, Any, Optional
from pathlib import Path

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.messages import HumanMessage, AIMessage
from loguru import logger

from .document_processor import DocumentProcessor

class ImprovedTrafficAdvisor:
    def __init__(self, google_api_key: str, model_name: str = "gemini-1.5-flash"):
        """
        ê°œì„ ëœ êµí†µì‚¬ê³  ìë¬¸ ì±—ë´‡ ì´ˆê¸°í™”
        """
        self.google_api_key = google_api_key
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=google_api_key,
            temperature=0.2,
            convert_system_message_to_human=True
        )
        
        # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (ì„ íƒì )
        try:
            self.doc_processor = DocumentProcessor(google_api_key)
            self.vectorstore = self.doc_processor.load_vectorstore()
        except:
            self.doc_processor = None
            self.vectorstore = None
            logger.warning("ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨ - ì¼ë°˜ ëª¨ë“œë¡œ ë™ì‘")
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.memory = ConversationBufferWindowMemory(
            k=3,  # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ê¸°ì–µ
            memory_key="chat_history",
            return_messages=True
        )
        
        # í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self._setup_prompts()
        
        logger.info("ê°œì„ ëœ êµí†µì‚¬ê³  ìë¬¸ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_prompts(self):
        """ê°„ë‹¨í•œ ì§„ë‹¨ìš© í”„ë¡¬í”„íŠ¸ ì„¤ì •"""
        
        # ì´ˆê¸° ì§„ë‹¨ í”„ë¡¬í”„íŠ¸ (ì§ˆë¬¸ ìµœì†Œí™”)
        self.quick_diagnosis_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ êµí†µì‚¬ê³  ì „ë¬¸ ìë¬¸ì‚¬ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ê°„ë‹¨í•˜ê³  ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ ì¡°ì–¸**ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ìƒí™©: {user_input}
ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: {image_analysis}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **ê°„ê²°í•˜ê²Œ** ë‹µë³€í•´ì£¼ì„¸ìš”:

## ğŸš— ì‚¬ê³  ìƒí™© ìš”ì•½
[ì‚¬ê³  ìƒí™©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]

## âš–ï¸ ì˜ˆìƒ ê³¼ì‹¤ë¹„ìœ¨
[ì¼ë°˜ì ì¸ ê³¼ì‹¤ë¹„ìœ¨ê³¼ ê°„ë‹¨í•œ ê·¼ê±°]

## ğŸ“‹ ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
1. [ê°€ì¥ ìš°ì„ ì ìœ¼ë¡œ í•´ì•¼ í•  ì¼]
2. [ë‘ ë²ˆì§¸ë¡œ ì¤‘ìš”í•œ ì¡°ì¹˜]
3. [ì„¸ ë²ˆì§¸ ì¡°ì¹˜ì‚¬í•­]

## ğŸ’¡ ì£¼ìš” í¬ì¸íŠ¸
[ê³¼ì‹¤ ë¹„ìœ¨ì— ì˜í–¥ì„ ì£¼ëŠ” í•µì‹¬ ìš”ì†Œ 1-2ê°œ]

---
**ë” ìì„¸í•œ ë¶„ì„ì„ ì›í•˜ì‹œë©´ "ìƒì„¸ ë¶„ì„ ìš”ì²­"ì´ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.**

âš ï¸ ì •í™•í•œ ë²•ë¥  ìë¬¸ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
""")
        
        # ìƒì„¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        self.detailed_analysis_prompt = ChatPromptTemplate.from_template("""
ì‚¬ìš©ìê°€ ìƒì„¸ ë¶„ì„ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. 
êµí†µì‚¬ê³  ì „ë¬¸ê°€ë¡œì„œ ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ê¸°ì¡´ ëŒ€í™”: {chat_history}
ì‚¬ìš©ì ìš”ì²­: {user_input}

ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:

## ğŸ” ë²•ë¥ ì  ë¶„ì„
- ì ìš© ê°€ëŠ¥í•œ ë„ë¡œêµí†µë²• ì¡°í•­
- ìœ ì‚¬ íŒë¡€ (ìˆë‹¤ë©´)
- ê³¼ì‹¤ ë¹„ìœ¨ ê²°ì • ìš”ì¸

## ğŸ“Š ê³¼ì‹¤ë¹„ìœ¨ ìƒì„¸ ë¶„ì„
- Aì°¨ëŸ‰ ê³¼ì‹¤ ìš”ì¸
- Bì°¨ëŸ‰ ê³¼ì‹¤ ìš”ì¸
- ì¡°ì • ê°€ëŠ¥í•œ ìš”ì†Œë“¤

## ğŸ›¡ï¸ ëŒ€ì‘ ì „ëµ
- ë³´í—˜ì‚¬ ëŒ€ì‘ ë°©ë²•
- í•„ìš”í•œ ì¦ê±° ìë£Œ
- ì£¼ì˜ì‚¬í•­

## â“ ì¶”ê°€ í™•ì¸ì‚¬í•­
[ì •í™•í•œ íŒë‹¨ì„ ìœ„í•´ í•„ìš”í•œ ì¶”ê°€ ì •ë³´ 2-3ê°€ì§€ë§Œ]

í•„ìš”í•˜ë‹¤ë©´ ì¶”ê°€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.
""")
    
    def quick_diagnosis(self, user_input: str, image_analysis: str = "") -> Dict[str, Any]:
        """ë¹ ë¥¸ ì´ˆê¸° ì§„ë‹¨"""
        try:
            # ê°„ë‹¨í•œ ì§„ë‹¨ ì²´ì¸
            chain = LLMChain(llm=self.llm, prompt=self.quick_diagnosis_prompt)
            
            result = chain.run(
                user_input=user_input,
                image_analysis=image_analysis or "ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
            )
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.memory.chat_memory.add_user_message(user_input)
            self.memory.chat_memory.add_ai_message(result)
            
            return {
                "answer": result,
                "type": "quick_diagnosis",
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"ë¹ ë¥¸ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "type": "error",
                "status": "error",
                "error": str(e)
            }
    
    def detailed_analysis(self, user_input: str) -> Dict[str, Any]:
        """ìƒì„¸ ë¶„ì„ ì œê³µ"""
        try:
            # ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
            chat_history = "\n".join([
                f"{'ì‚¬ìš©ì' if isinstance(msg, HumanMessage) else 'ìë¬¸ì‚¬'}: {msg.content}"
                for msg in self.memory.chat_memory.messages[-6:]  # ìµœê·¼ 6ê°œ
            ])
            
            # ìƒì„¸ ë¶„ì„ ì²´ì¸
            chain = LLMChain(llm=self.llm, prompt=self.detailed_analysis_prompt)
            
            result = chain.run(
                chat_history=chat_history,
                user_input=user_input
            )
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.memory.chat_memory.add_user_message(user_input)
            self.memory.chat_memory.add_ai_message(result)
            
            return {
                "answer": result,
                "type": "detailed_analysis", 
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "answer": "ìƒì„¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "type": "error",
                "status": "error",
                "error": str(e)
            }
    
    def analyze_with_context(self, user_input: str, image_analysis: str = "") -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)"""
        
        # ìƒì„¸ ë¶„ì„ ìš”ì²­ì¸ì§€ í™•ì¸
        detail_keywords = ["ìƒì„¸", "ë” ìì„¸íˆ", "ìƒì„¸ ë¶„ì„", "ë” ì•Œê³  ì‹¶", "ìì„¸í•œ ì„¤ëª…"]
        is_detail_request = any(keyword in user_input for keyword in detail_keywords)
        
        if is_detail_request:
            return self.detailed_analysis(user_input)
        else:
            return self.quick_diagnosis(user_input, image_analysis)
    
    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.memory.clear()
        logger.info("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    google_api_key = os.getenv("GOOGLE_API_KEY")
    
    if not google_api_key:
        print("GOOGLE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
        return
    
    # ê°œì„ ëœ ìë¬¸ì‚¬ ì´ˆê¸°í™”
    advisor = ImprovedTrafficAdvisor(google_api_key)
    
    print("ğŸš— ê°œì„ ëœ êµí†µì‚¬ê³  ìë¬¸ ì±—ë´‡ (MVP)")
    print("ê°„ë‹¨í•œ ìƒí™© ì„¤ëª…ë§Œìœ¼ë¡œë„ ì¦‰ì‹œ ì¡°ì–¸ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print("'quit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\n")
    
    while True:
        user_input = input("\nğŸ’¬ ì‚¬ê³  ìƒí™©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”: ")
        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            break
        
        if not user_input.strip():
            continue
        
        # ë¶„ì„ ì‹¤í–‰
        print("\nğŸ” ë¶„ì„ ì¤‘...")
        result = advisor.analyze_with_context(user_input)
        print(f"\nğŸ¤– ìë¬¸ì‚¬:\n{result['answer']}")

if __name__ == "__main__":
    main()
